"""
æµ‹è¯•LLMæ¥å…¥
ä½¿ç”¨GPT-5é€šè¿‡ç¬¬ä¸‰æ–¹ä»£ç†
"""

import sys
import os
sys.path.insert(0, os.path.dirname(__file__))

from src.core.llm_client import create_llm_client, PromptTemplates


def test_llm_connection():
    """æµ‹è¯•LLMè¿æ¥"""
    
    print("="*70)
    print("  æµ‹è¯•DeepSeekæ¥å…¥")
    print("="*70)
    print()
    
    # é…ç½®
    API_KEY = "sk-c04296145c2545588fee614c8e9ac3fb"
    API_BASE = "https://api.deepseek.com/v1"  # DeepSeekå®˜æ–¹API
    MODEL = "deepseek-chat"  # DeepSeek Chatæ¨¡å‹
    
    print(f"ğŸ“¡ é…ç½®ä¿¡æ¯:")
    print(f"  API Key: {API_KEY[:20]}...")
    print(f"  API Base: {API_BASE}")
    print(f"  æ¨¡å‹: {MODEL}")
    print()
    
    try:
        # 1. åˆ›å»ºå®¢æˆ·ç«¯
        print("1ï¸âƒ£  åˆ›å»ºLLMå®¢æˆ·ç«¯...")
        llm_client = create_llm_client(
            provider='openai',
            api_key=API_KEY,
            model=MODEL,
            api_base=API_BASE
        )
        print("  âœ… å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        print()
        
        # 2. æµ‹è¯•ç®€å•ç”Ÿæˆ
        print("2ï¸âƒ£  æµ‹è¯•ç®€å•æ–‡æœ¬ç”Ÿæˆ...")
        prompt = "è¯·ç”¨ä¸€å¥è¯ä»‹ç»è‹å·æ‹™æ”¿å›­çš„ç‰¹è‰²ã€‚"
        print(f"  æç¤ºè¯: {prompt}")
        print()
        
        response = llm_client.generate(
            prompt=prompt,
            temperature=0.7,
            max_tokens=100
        )
        
        print("  å“åº”:")
        print(f"  {response}")
        print()
        print("  âœ… ç®€å•ç”Ÿæˆæµ‹è¯•æˆåŠŸï¼")
        print()
        
        # 3. æµ‹è¯•POIåˆ†æï¼ˆç»“æ„åŒ–ï¼‰
        print("3ï¸âƒ£  æµ‹è¯•POIæ·±åº¦åˆ†æ...")
        
        poi_info = {
            'name': 'æ‹™æ”¿å›­',
            'type': 'attraction',
            'rating': 4.7,
            'review_count': 25000,
            'tags': ['æ±Ÿå—å›­æ—', 'ä¸–ç•Œæ–‡åŒ–é—äº§', 'æ˜ä»£å»ºç­‘']
        }
        
        user_profile = {
            'purpose': {'culture': 0.9, 'leisure': 0.7},
            'pace': {'slow': 0.9}
        }
        
        context = {
            'visited': [],
            'fatigue': 0.0
        }
        
        prompt = PromptTemplates.poi_analysis(poi_info, user_profile, context)
        
        print("  ç”ŸæˆPOIæ¨èç†ç”±...")
        response = llm_client.generate(
            prompt=prompt,
            temperature=0.7,
            max_tokens=300
        )
        
        print()
        print("  GPT-5åˆ†æç»“æœ:")
        print("  " + "-"*60)
        print(f"  {response}")
        print("  " + "-"*60)
        print()
        print("  âœ… POIåˆ†ææµ‹è¯•æˆåŠŸï¼")
        print()
        
        # 4. æµ‹è¯•é£é™©è§£é‡Š
        print("4ï¸âƒ£  æµ‹è¯•é£é™©è§£é‡Š...")
        
        risk_info = {
            'choice_name': 'å¤ªæ¹–æ¹¿åœ°å…¬å›­',
            'risk_type': 'return',
            'finish_time': '17:30',
            'return_time': 1.0,
            'arrive_time': '18:30',
            'deadline': '18:00',
            'late_by': 0.5
        }
        
        prompt = PromptTemplates.risk_explanation(risk_info)
        
        print("  ç”Ÿæˆé£é™©è§£é‡Š...")
        response = llm_client.generate(
            prompt=prompt,
            temperature=0.7,
            max_tokens=200
        )
        
        print()
        print("  GPT-5é£é™©è§£é‡Š:")
        print("  " + "-"*60)
        print(f"  {response}")
        print("  " + "-"*60)
        print()
        print("  âœ… é£é™©è§£é‡Šæµ‹è¯•æˆåŠŸï¼")
        print()
        
        # æ€»ç»“
        print("="*70)
        print("  âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼GPT-5æ¥å…¥æˆåŠŸï¼")
        print("="*70)
        print()
        print("ğŸ“Š æµ‹è¯•ç»“æœ:")
        print("  â€¢ å®¢æˆ·ç«¯è¿æ¥: âœ…")
        print("  â€¢ ç®€å•æ–‡æœ¬ç”Ÿæˆ: âœ…")
        print("  â€¢ POIæ·±åº¦åˆ†æ: âœ…")
        print("  â€¢ é£é™©è§£é‡Š: âœ…")
        print()
        print("ğŸ¯ LLMå·²å°±ç»ªï¼Œå¯ä»¥é›†æˆåˆ°ç³»ç»Ÿä¸­ï¼")
        
    except Exception as e:
        print(f"  âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        print()
        print("ğŸ’¡ å¯èƒ½çš„é—®é¢˜:")
        print("  1. æ£€æŸ¥API Keyæ˜¯å¦æ­£ç¡®")
        print("  2. æ£€æŸ¥API Base URLæ˜¯å¦æ­£ç¡®")
        print("  3. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("  4. ç¡®è®¤å·²å®‰è£…openaiåº“: pip install openai")


if __name__ == "__main__":
    test_llm_connection()
